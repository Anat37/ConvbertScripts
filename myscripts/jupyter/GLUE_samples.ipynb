{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Trainer, GlueDataset, DataCollatorWithPadding, GlueDataTrainingArguments\n",
    "from transformers import AlbertTokenizer, ConvbertForSequenceClassification, ConvbertModel\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import os\n",
    "\n",
    "data_sub_dir = 'CoLA'\n",
    "\n",
    "model_dir = 'E:\\ConvbertData\\glue_models\\convbert_12/' + data_sub_dir\n",
    "albert_model_dir = 'E:/ConvbertData/glue_models/albert_ready/' + data_sub_dir\n",
    "\n",
    "def get_last_checkpoint(dir_name):\n",
    "    max_check = -1\n",
    "    result = None\n",
    "    for filename in os.listdir(dir_name):\n",
    "        if 'checkpoint' in filename:\n",
    "            step = int(filename.split('-')[1])\n",
    "            if step > max_check:\n",
    "                max_check = step\n",
    "                result = filename\n",
    "    return os.path.join(dir_name, result)\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "model = ConvbertForSequenceClassification.from_pretrained(get_last_checkpoint(model_dir))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "data_args = GlueDataTrainingArguments(\n",
    "    data_dir='E:/ConvbertData/glue_data/' + data_sub_dir,\n",
    "    task_name='cola'\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertForSequenceClassification, AutoModelLSTMForSequenceClassification,AutoModelForSequenceClassification\n",
    "\n",
    "albert_model = AutoModelForSequenceClassification.from_pretrained(get_last_checkpoint(albert_model_dir))\n",
    "albert_model = albert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "\n",
    "dataset = GlueDataset(data_args, tokenizer=tokenizer, mode=\"dev\")\n",
    "\n",
    "data = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    collate_fn=default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(inputs):\n",
    "    for k, v in inputs.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            inputs[k] = v.to(device)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albert\n",
      "0.18414322250639387\n",
      "0.26359832635983266\n",
      "0.2727272727272727\n",
      "convbert\n",
      "0.309462915601023\n",
      "0.3891213389121339\n",
      "0.36363636363636365\n",
      "avg\n",
      "7.920421860019175\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "count = 0\n",
    "\n",
    "albert_fail_len = defaultdict(int)\n",
    "albert_correct_len = defaultdict(int)\n",
    "convbert_fail_len = defaultdict(int)\n",
    "convbert_correct_len = defaultdict(int)\n",
    "avg_len = 0\n",
    "\n",
    "albert_correct_count = 0\n",
    "albert_fail_count = 0\n",
    "convbert_correct_count = 0\n",
    "convbert_fail_count = 0\n",
    "\n",
    "for inputs in data:\n",
    "    count += 1\n",
    "    tokens = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)\n",
    "    #print()\n",
    "    labels = inputs['labels'][0].item()\n",
    "    #print(inputs['labels'])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**prepare_inputs(inputs))\n",
    "        conv_logits = outputs[1:][0].argmax()\n",
    "        \n",
    "        outputs = albert_model(**prepare_inputs(inputs))\n",
    "        albert_logits = outputs[1:][0].argmax().item()\n",
    "        \n",
    "        ln = len(tokens.split(' '))\n",
    "        avg_len += ln\n",
    "        if albert_logits == labels:\n",
    "            albert_correct_len[ln // 10] += 1\n",
    "            albert_correct_count += 1\n",
    "        if albert_logits != labels:\n",
    "            albert_fail_len[ln // 10] += 1\n",
    "            albert_fail_count += 1\n",
    "        if conv_logits == labels:\n",
    "            convbert_correct_len[ln // 10] += 1\n",
    "            convbert_correct_count += 1\n",
    "        if conv_logits != labels:\n",
    "            convbert_fail_len[ln // 10] += 1\n",
    "            convbert_fail_count += 1\n",
    "        if (albert_logits == labels and conv_logits != labels) or (albert_logits != labels and conv_logits == labels):\n",
    "            pass\n",
    "            #print(tokens)\n",
    "            #print('label:{}, albert: {}, convbert: {}'.format(labels, albert_logits, conv_logits))\n",
    "            \n",
    "            \n",
    "def print_hist(corrects, fails):\n",
    "    for ln, cnt in sorted(fails.items()):\n",
    "        print(cnt / (corrects[ln] + cnt))\n",
    "        \n",
    "\n",
    "print('albert')\n",
    "print_hist(albert_correct_len, albert_fail_len)\n",
    "#print(sorted(albert_correct_len.items()))\n",
    "\n",
    "print('convbert')\n",
    "print_hist(convbert_correct_len, convbert_fail_len)\n",
    "#print(sorted(convbert_correct_len.items()))\n",
    "\n",
    "print('avg')\n",
    "print(avg_len/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Cola' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a4da435b227d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mCola\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0malbert\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m37\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m37\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m26\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m17\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mconvbert\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m29\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m71\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m77\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m65\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m37\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m23\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m17\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Cola' is not defined"
     ]
    }
   ],
   "source": [
    "Cola\n",
    "albert\n",
    "[(0, 3), (1, 15), (2, 37), (3, 50), (4, 37), (5, 26), (6, 17), (7, 11), (8, 7), (9, 2), (10, 3), (11, 2), (12, 2), (13, 1)]\n",
    "convbert\n",
    "[(0, 3), (1, 29), (2, 71), (3, 77), (4, 65), (5, 37), (6, 23), (7, 17), (8, 9), (9, 2), (10, 4), (11, 1), (12, 4), (13, 1)]\n",
    "avg\n",
    "41.830297219558965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit",
   "language": "python",
   "name": "python36564bit5f07781c00224688be8c373277587870"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
